{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F94oQ4ALLjHK",
        "outputId": "03177cf5-e0df-4200-9cff-3a53fbf6d1c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Human Image Detection Eval**"
      ],
      "metadata": {
        "id": "_ztnkOQZLFZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/semajyllek/ioqm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PpTZ-U-LcTy",
        "outputId": "443b820c-89b4-4889-fbe0-6461ff5b2b31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ioqm'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 88 (delta 47), reused 64 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (88/88), 20.30 KiB | 5.08 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6yOY6dbK96n",
        "outputId": "9a85397c-00e9-4ed4-a40b-3939eaab43a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ioqm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8B8QT_rLV2f",
        "outputId": "d65fe940-35b7-4bcb-ecd2-1464f837414d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ioqm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from utils import parse_objects_and_quantities\n",
        "from pathlib import Path\n",
        "import gradio as gr\n",
        "import random\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "wS6rIt-cMTA9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code to launch gradio app and pull a random image and save result\n",
        "def get_random_image(img_path, max_images=16175):\n",
        "  rand_n = random.sample(range(1, max_images), 1)[0]\n",
        "  rand_img = img_path / os.listdir(img_path)[rand_n]\n",
        "  return rand_img\n",
        "\n",
        "\n",
        "def get_expected_labels(img_path) -> List[str]:\n",
        "  expected_obs = parse_objects_and_quantities(img_path.stem.replace('_', ' '))\n",
        "  return list(expected_obs.keys())\n",
        "\n",
        "def eval_interface(img_path: Path, score_path: Path):\n",
        "  expected_labels = get_expected_labels(img_path)\n",
        "\n",
        "  def process_counts(*counts):\n",
        "    count_dict = {}\n",
        "    for labl, cnt in zip(expected_labels, counts):\n",
        "      count_dict[labl] = cnt\n",
        "\n",
        "    with open(score_path, 'a') as f:\n",
        "      json.dump({img_path.name: count_dict}, f)\n",
        "      f.write('\\n')\n",
        "    demo.close()\n",
        "\n",
        "\n",
        "  with gr.Blocks() as demo:\n",
        "    gr.Image(img_path)\n",
        "    counts = []\n",
        "    for labl in expected_labels:\n",
        "      counts.append(gr.Number(label=labl))\n",
        "\n",
        "    submit_btn = gr.Button(\"submit counts\")\n",
        "    submit_btn.click(fn=process_counts, inputs=counts, outputs=None)\n",
        "\n",
        "  demo.launch()\n"
      ],
      "metadata": {
        "id": "a0nWpXVpLV5J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to generated images of both original and v2 datasets and paths to save evaluations\n",
        "ioqm_data_root = Path(\"/content/drive/MyDrive/ioqm_data\")\n",
        "\n",
        "# 16K image data\n",
        "gen_data_root = ioqm_data_root / \"generated_images\"\n",
        "sd_v1_5_img_folder = gen_data_root / \"stable-diffusion-v1-5_images\"\n",
        "sd_xl_refiner_1_img_folder = gen_data_root / \"stable-diffusion-xl-refiner-1.0_images\"\n",
        "wuerstchen_img_folder = gen_data_root / \"wuerstchen_images\"\n",
        "\n",
        "# 4K image data\n",
        "gen_data_root_v2 = ioqm_data_root / \"generated_images_v2\"\n",
        "sd_v1_5_img_v2_folder = gen_data_root_v2 / \"mini_prompts_v2_stable-diffusion-v1-5_images\"\n",
        "sd_xl_refiner_1_img_v2_folder = gen_data_root_v2 / \"mini_prompts_v2_stable-diffusion-xl-refiner-1.0_images\"\n",
        "wuerstchen_img_folder_v2 = gen_data_root_v2 / \"mini_prompts_v2_wuerstchen_images\"\n",
        "\n",
        "# path to save evals\n",
        "human_eval_root = ioqm_data_root / \"eval\" / \"human_scores\"\n",
        "human_eval_v2_root = ioqm_data_root / \"eval_v2\" / \"human_scores\""
      ],
      "metadata": {
        "id": "g51UBR4sLV7M"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to be configured for each experiment/session\n",
        "img_folder = wuerstchen_img_folder_v2\n",
        "human_scores_path = human_eval_root / f\"{img_folder.name}_human_scores\"\n",
        "max_images = len(os.listdir(img_folder))"
      ],
      "metadata": {
        "id": "hdeOi-Ic-Ro1"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_img_path = get_random_image(img_folder, max_images=max_images)\n",
        "eval_interface(rand_img_path, human_scores_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "o9WE0OUyLV9i",
        "outputId": "7bc83ce9-1f55-4eea-ba4f-217392bcb000"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f563e06ec07bda6519.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f563e06ec07bda6519.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}