"""
author: James Kelly
date: 09/28/2023
uses object detection model on images generated by a text-to-image model 
to evaluate the quality of the text-to-image model by comparing the object 
counts in the prompt vs the generated image
"""

from typing import Any, Dict, List, Optional, Tuple
from utils import parse_objects_and_quantities
from transformers import pipeline
from functools import partial
import concurrent.futures
from pathlib import Path
import json
import os


WORKER_DIVISOR = 4


def run_eval(img_folder: str, detector_model_id: Optional[Any] = None, mp: bool = False) -> Tuple[Dict[str, float], Dict[str, float]]:
    ioqms = dict(dict())
    detector = get_detector(detector_model_id)
    image_files = [os.path.join(img_folder, img_file) for img_file in os.listdir(img_folder)]

    # Create a partial function with fixed detector argument for mapping
    evaluate_single_image_partial = partial(evaluate_single_image, detector=detector)

    if mp:
        with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() // WORKER_DIVISOR) as executor:
            results = executor.map(evaluate_single_image_partial, image_files)
    else:
       results = map(evaluate_single_image_partial, image_files)

    for prompt, ioqm_result in results:
        ioqms[prompt] = ioqm_result

    return ioqms


def get_detector(model_id: Optional[str] = None) -> Any:
    if model_id is None or (model_id == "facebook/detr-resnet-50"):
        return pipeline("object-detection", model="facebook/detr-resnet-50")
    elif model_id == "facebook/detr-resnet-101":
        return pipeline("object-detection", model="facebook/detr-resnet-101")
    elif model_id == "facebook/detr-resnet-50-panoptic":
        return pipeline("object-detection", model="facebook/detr-resnet-50-panoptic")
    elif model_id == 'jozhang97/deta-swin-large':
        from detector_models.swin import swin_detector
        return swin_detector
    elif model_id == 'yolo':
        from detector_models.yolov8 import yolov8_detector
        return yolov8_detector
    else:
        raise ValueError(f"Invalid detector model_id: {model_id}")


def evaluate_single_image(img_path: Path, detector: Any, ) -> Tuple[str, Dict[str, float]]:
    detected_quants = get_obj_quants(detector(img_path))
    return get_prompt_and_scores(img_path, detected_quants)


def get_prompt_and_scores(img_path: Path, detected_quants: Dict[str, int]) -> Tuple[str, Dict[str, float]]:
    prompt = Path(img_path).stem.replace('_', ' ')
    expected_quants = parse_objects_and_quantities(prompt)
    h_ioqm = hard_ioqm(expected_quants, detected_quants)
    s_ioqm = soft_ioqm(expected_quants, detected_quants)
    ioqm_result = {'hard_ioqm': h_ioqm, 'soft_ioqm': s_ioqm}
    return prompt, ioqm_result


def get_obj_quants(result: List[Dict[str, float]]) -> Dict[str, float]:
    obj_quants = dict()
    for res in result:
        if isinstance(res, dict):
            obj_quants[res['label']] = obj_quants.get(res['label'], 0) + 1
        else:
            obj_quants[res.category.name] = obj_quants.get(res.category.name, 0) + 1

    return obj_quants
    


def check_object(obj: str, detected_obs: Dict[str, int]) -> Optional[str]:
  for det_obj in detected_obs:
    if len(obj) > len(det_obj):
      if obj.startswith(det_obj):
        return det_obj
    if det_obj.startswith(obj):
        return det_obj

  return None


def hard_ioqm(expected_obs: Dict[str, int], detected_obs: Dict[str, int]) -> float:
    """
      desc: calculates num of objects with correct quantities / num objects, 0 to 1.0
      expected = dict_items([('skis', 1), ('snowboard', 3), ('backpack', 2)])
      detected = dict_items([('snowboards', 3), ('backpacks', 5), ('ties', 3)])
      hard_ioqm = 1 / 3 = 0.3333
    """
    num_exp_objects = float(len(expected_obs)) 
    assert num_exp_objects > 0, "no expected objects" # avoids div by 0

    ioqm = 0.0
    for obj, exp_quant in expected_obs.items():
        det_obj = check_object(obj, detected_obs)
        if det_obj is None:
            continue
        if detected_obs[det_obj] != exp_quant:
            continue
        ioqm += 1
    return ioqm / num_exp_objects




def soft_ioqm(expected_obs: Dict[str, int], detected_obs: Dict[str, int]) -> float:
    """
        desc: calculates average num of objects / num expected objects, 0 to 1.0
        expected = dict_items([('skis', 1), ('snowboard', 3), ('backpack', 2)])
        detected = dict_items([('snowboards', 5), ('backpacks', 5), ('ties', 3)])
        soft_ioqm = 0/1 + 3/5 + 2/5 = 0.6 / 3 = 0.2

        max is 1.0, so even if there are more detected objects than expected, 
        the score is bound between 0 and 1.0
    """
    num_exp_objects = float(len(expected_obs)) 
    assert num_exp_objects > 0, "no expected objects" # avoids div by 0
    
    ioqm = 0.0
    for obj, exp_quant in expected_obs.items():
        det_obj = check_object(obj, detected_obs)
        if det_obj is None:
            continue
        ioqm += detected_obs[det_obj] / float(exp_quant)
    return min(1.0, ioqm / num_exp_objects)


def save_scores_jsonl(ioqm_scores: Dict[str, Dict[str, float]], save_path: Path, mode: str = 'w') -> None:
    with open(save_path, mode=mode) as fp:
        for p, scores in sorted(ioqm_scores.items(), key=lambda x: x[0]):
            json.dump({p: scores}, fp)
            fp.write('\n')






if __name__ == "__main__":
   import argparse
   parser = argparse.ArgumentParser()
   parser.add_argument("--img_folder", type=str)
   parser.add_argument("--detector_model_id", type=str, default=None)
   parser.add_argument("--save_path", type=str)
   parser.add_argument("--mp", action="store_true")
   args = parser.parse_args()
   
   scores = run_eval(args.img_folder, mp=args.mp, detector_model_id=args.detector_model_id)

   print(scores)
   save_scores_jsonl(scores, args.save_path, mode='w')
   
   # img_folder = "/Users/jameskelly/Downloads/stable-diffusion-xl-refiner-1.0_images_v1"
   # save_path = "/Users/jameskelly/Downloads/stable-diffusion-xl-refiner-1.0_v1_yolov5_ioqm_scores.jsonl"

